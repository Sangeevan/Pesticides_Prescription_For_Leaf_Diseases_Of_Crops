{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining necessary file paths\n",
    "\n",
    "model_path = '../Model/Pesticides_Prescription_Model.sav'\n",
    "labels_path = '../Model/Class_Labels_Pesticides_Prescription_Model.csv'\n",
    "test_data_dir = '../Dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restoring the model\n",
    "\n",
    "def initialize_alexnet(model_name, num_classes, feature_extract=True, use_pretrained=True):\n",
    "\n",
    "  model_ft = None\n",
    "  input_size = 0\n",
    "\n",
    "  if model_name == \"alexnet\":\n",
    "    model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "\n",
    "    if feature_extract:\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "\n",
    "    input_size = 224\n",
    "  else:\n",
    "        print(\"Model name is invalid!\")\n",
    "        exit()\n",
    "\n",
    "  return model_ft,input_size\n",
    "\n",
    "model, _ = initialize_alexnet(\"alexnet\", num_classes=15)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the labels file\n",
    "\n",
    "labels_df = pd.read_csv(labels_path, header=None, names=['idx','Label'])\n",
    "labels_dict = dict(zip(labels_df.idx, labels_df.Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the output\n",
    "\n",
    "def predict(img):\n",
    "    transform = transforms.Compose([            \n",
    "    transforms.Resize(256),                    \n",
    "    transforms.CenterCrop(224),                \n",
    "    transforms.ToTensor(),                     \n",
    "    transforms.Normalize(                      \n",
    "    mean=[0.485, 0.456, 0.406],                \n",
    "    std=[0.229, 0.224, 0.225]                  \n",
    "    )])\n",
    "\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)  \n",
    "    out = model(batch_t)\n",
    "    _, index = torch.max(out, 1)\n",
    "    \n",
    "    return index\n",
    "\n",
    "def get_label(labels_dict, idx=-1):\n",
    "    if (idx>=0 and idx<=14):\n",
    "        label = labels_dict[idx]\n",
    "    else:\n",
    "        label = ''\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting actual and predicted values for the test dataset\n",
    "\n",
    "actual_label_list = []\n",
    "predicted_lebel_list = []\n",
    "list_test_data_dir = listdir(test_data_dir)\n",
    "for leaf_image_dir in list_test_data_dir :\n",
    "        image_list = listdir(f\"{test_data_dir}/{leaf_image_dir}\")\n",
    "        for image in image_list:\n",
    "          image_file = f\"{test_data_dir}/{leaf_image_dir}/{image}\"\n",
    "          if image_file.endswith(\".jpg\") == True or image_file.endswith(\".JPG\") == True:\n",
    "            actual_label_list.append(leaf_image_dir)\n",
    "            img = Image.open(image_file)\n",
    "            pred_idx = predict(img)\n",
    "            predicted_lebel = get_label(labels_dict, pred_idx.numpy()[0])\n",
    "            predicted_lebel_list.append(predicted_lebel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  1, 148,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  4,   0,  94,   0,   0,   0,   0,   1,   0,   0,   0,   1,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  14,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,   0,   0,   2,  92,   1,   0,   0,   3,   0,   0,   0,   0,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0, 210,   0,   1,   1,   0,   0,   1,   1,\n",
       "          0,   0],\n",
       "       [  2,   0,   0,   0,   2,  16,  52,   0,   6,   1,   0,  15,   3,\n",
       "          2,   1],\n",
       "       [  0,   0,   0,   0,   0,   1,   0, 158,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   8,   3,   0,   4, 165,   1,   0,   5,   1,\n",
       "          4,   1],\n",
       "       [  1,   0,   0,   0,   0,   2,   0,   1,   2,  78,   0,   6,   0,\n",
       "          2,   4],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   1,   0,   0,  37,   0,   0,\n",
       "          0,   0],\n",
       "       [  5,   0,   0,   0,   0,   0,   0,   1,   0,   0,   2, 169,   1,\n",
       "          0,   0],\n",
       "       [  4,   0,   0,   0,   0,   2,   0,  17,   0,   0,   0,   7, 105,\n",
       "          6,   0],\n",
       "       [  4,   0,   0,   0,   1,   0,   0,   7,   0,   0,   1,   2,  13,\n",
       "        139,   2],\n",
       "       [  1,   0,   0,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,\n",
       "          0, 162]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(actual_label_list, predicted_lebel_list)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8978102189781022"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "\n",
    "accuracy = (cm.trace()/cm.sum())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81147541, 0.98666667, 1.        , 0.875     , 0.87619048,\n",
       "       0.88983051, 1.        , 0.82722513, 0.93220339, 0.96296296,\n",
       "       0.925     , 0.82038835, 0.84677419, 0.9025974 , 0.95294118])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precission\n",
    "\n",
    "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9072837111321501"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Macro average precision\n",
    "\n",
    "macro_average_precision = np.mean(precision)\n",
    "macro_average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98019802, 0.99328859, 0.94      , 0.875     , 0.92      ,\n",
       "       0.98130841, 0.52      , 0.99371069, 0.859375  , 0.8125    ,\n",
       "       0.97368421, 0.9494382 , 0.74468085, 0.82248521, 0.98181818])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "\n",
    "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8898324910800646"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Macro average recall\n",
    "\n",
    "macro_average_recall = np.mean(recall)\n",
    "macro_average_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88789238, 0.98996656, 0.96907216, 0.875     , 0.89756098,\n",
       "       0.93333333, 0.68421053, 0.90285714, 0.89430894, 0.88135593,\n",
       "       0.94871795, 0.88020833, 0.79245283, 0.86068111, 0.96716418])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 score\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.890985490407892"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Macro average F1 score\n",
    "\n",
    "macro_average_F1 = np.mean(F1)\n",
    "macro_average_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "    Bell_pepper__Bacterial_spot       0.81      0.98      0.89       101\n",
      "           Bell_pepper__Healthy       0.99      0.99      0.99       149\n",
      "           Potato__Early_blight       1.00      0.94      0.97       100\n",
      "                Potato__Healthy       0.88      0.88      0.88        16\n",
      "            Potato__Late_blight       0.88      0.92      0.90       100\n",
      "         Tomato__Bacterial_spot       0.89      0.98      0.93       214\n",
      "           Tomato__Early_blight       1.00      0.52      0.68       100\n",
      "                Tomato__Healthy       0.83      0.99      0.90       159\n",
      "            Tomato__Late_blight       0.93      0.86      0.89       192\n",
      "              Tomato__Leaf_mold       0.96      0.81      0.88        96\n",
      "           Tomato__Mosaic_virus       0.93      0.97      0.95        38\n",
      "     Tomato__Septoria_leaf_spot       0.82      0.95      0.88       178\n",
      "            Tomato__Target_spot       0.85      0.74      0.79       141\n",
      "Tomato__Two_spotted_spider_mite       0.90      0.82      0.86       169\n",
      " Tomato__Yellow_leaf_curl_virus       0.95      0.98      0.97       165\n",
      "\n",
      "                       accuracy                           0.90      1918\n",
      "                      macro avg       0.91      0.89      0.89      1918\n",
      "                   weighted avg       0.90      0.90      0.89      1918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(actual_label_list, predicted_lebel_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
